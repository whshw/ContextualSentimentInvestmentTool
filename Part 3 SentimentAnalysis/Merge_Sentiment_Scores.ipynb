{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81800142029e5c30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T14:06:02.250000700Z",
     "start_time": "2023-08-22T14:06:02.235059500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 导入库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T14:07:40.247500900Z",
     "start_time": "2023-08-22T14:07:39.342114900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 选择NER阈值\n",
    "count = 'count_1'\n",
    "\n",
    "# 合并所有国家的情感分析数据\n",
    "path_Reuters = \"../Data/Sentiment_Scores/\" + count + \"/Reuters_Sentiment_Scores/*.csv\"\n",
    "path_MarketWatch = \"../Data/Sentiment_Scores/\" + count + \"/MW_Sentiment_Scores/*.csv\"\n",
    "path_CNN = \"../Data/Sentiment_Scores/\" + count + \"/CNN_Sentiment_Scores/*.csv\"\n",
    "path_TG = \"../Data/Sentiment_Scores/\" + count + \"/TG_Sentiment_Scores/*.csv\"\n",
    "\n",
    "def process_files(path, exclude_suffix=None):\n",
    "    lst_files = []\n",
    "\n",
    "    for fname in glob.glob(path):\n",
    "        if exclude_suffix:\n",
    "            if not fname.endswith(exclude_suffix):\n",
    "                lst_files.append(fname)\n",
    "        else:\n",
    "            lst_files.append(fname)\n",
    "\n",
    "    lst_files = sorted(lst_files)\n",
    "\n",
    "    df_sentiment = pd.concat(map(pd.read_csv, lst_files), ignore_index=True)\n",
    "    df_sentiment = df_sentiment.sort_values(by=['Date', 'Country'], ascending=True)\n",
    "    df_sentiment = df_sentiment.drop(['Unnamed: 0'], axis=1)\n",
    "    df_sentiment['Date'] = pd.to_datetime(df_sentiment['Date'])\n",
    "    df_sentiment = df_sentiment[~(df_sentiment['Date'] < '2012-01-01')]\n",
    "\n",
    "    return df_sentiment\n",
    "\n",
    "# 处理数据\n",
    "df_Reuters_sentiment = process_files(path_Reuters, \"_original.csv\")\n",
    "df_MW_sentiment = process_files(path_MarketWatch, \"_original.csv\")\n",
    "df_CNN_sentiment = process_files(path_CNN, \"_original.csv\")\n",
    "df_TG_sentiment = process_files(path_TG, \"_original.csv\")\n",
    "\n",
    "\n",
    "df_Reuters_sentiment.to_csv(r'../Data/Sentiment_Scores/{0}.csv'.format('Merged Sentiment Reuters'))\n",
    "df_MW_sentiment.to_csv(r'../Data/Sentiment_Scores/{0}.csv'.format('Merged Sentiment MW'))\n",
    "df_CNN_sentiment.to_csv(r'../Data/Sentiment_Scores/{0}.csv'.format('Merged Sentiment CNN'))\n",
    "df_TG_sentiment.to_csv(r'../Data/Sentiment_Scores/{0}.csv'.format('Merged Sentiment TG'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8872edb89ba2ea11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T14:07:48.020248100Z",
     "start_time": "2023-08-22T14:07:47.821221100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 读取CNN合并后的情感分数数据\n",
    "df_CNN_sentiment = pd.read_csv('../Data/Sentiment_Scores/Merged Sentiment CNN.csv')\n",
    "# 将CNN的国家名称中的“UnitedStates”改为“United Sates”\n",
    "df_CNN_sentiment['Country'] = df_CNN_sentiment['Country'].replace('UnitedStates', 'United States')\n",
    "# 将CNN的国家名称中的“UnitedKingdom”改为“United Kingdom”\n",
    "df_CNN_sentiment['Country'] = df_CNN_sentiment['Country'].replace('UnitedKingdom', 'United Kingdom')\n",
    "# 将CNN的国家名称中的“SouthKorea”改为“South Korea”\n",
    "df_CNN_sentiment['Country'] = df_CNN_sentiment['Country'].replace('SouthKorea', 'South Korea')\n",
    "# 将CNN的国家名称中的“NewZealand”改为“New Zealand”\n",
    "df_CNN_sentiment['Country'] = df_CNN_sentiment['Country'].replace('NewZealand', 'New Zealand')\n",
    "# 保存修改后的CNN情感分数数据\n",
    "df_CNN_sentiment.to_csv(r'../Data/Sentiment_Scores/{0}.csv'.format('Merged Sentiment CNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1f0f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为TG的文章的情感分数文件添加国家列\n",
    "import os\n",
    "\n",
    "lst_files = []\n",
    "\n",
    "# Path = \"../Data/Sentiment_Scores/count_1/TG_Sentiment_Scores/*.csv\"\n",
    "\n",
    "category_1 = '1_Finance'\n",
    "category_2 = '2_Politics'\n",
    "category_3 = '3_Sports'\n",
    "category_4 = '4_Health'\n",
    "# 为所有情感分数文件添加国家列\n",
    "category = category_4\n",
    "path_TG = \"../Data/Sentiment_Scores/ClassificationSentimentScores/\" + category + \"/TG_Sentiment_Scores/*.csv\"\n",
    "path_CNN = \"../Data/Sentiment_Scores/ClassificationSentimentScores/\" + category + \"/CNN_Sentiment_Scores/*.csv\"\n",
    "path_MW = \"../Data/Sentiment_Scores/ClassificationSentimentScores/\" + category + \"/MW_Sentiment_Scores/*.csv\"\n",
    "path_Reuters = \"../Data/Sentiment_Scores/ClassificationSentimentScores/\" + category + \"/Reuters_Sentiment_Scores/*.csv\"\n",
    "\n",
    "\n",
    "for fname in glob.glob(path_TG):\n",
    "    lst_files.append(fname)\n",
    "\n",
    "lst_files = sorted(lst_files)\n",
    "\n",
    "for file in lst_files:\n",
    "    file_name = os.path.basename(file)  # Get the file name from the full file path\n",
    "    country_name = os.path.splitext(file_name)[0]  # Remove the file extension\n",
    "    df = pd.read_csv(file)\n",
    "    df['Country'] = country_name\n",
    "    df= df[['Date', 'Country', 'LMD_Polarity', 'HIV4_Polarity', 'Vader_Polarity', 'FinBert_Polarity']]\n",
    "    df.to_csv(r'../Data/Sentiment_Scores/ClassificationSentimentScores/{0}/TG_Sentiment_Scores/{1}.csv'.format(category, country_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb31a089f36939ba",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "category_1 = '1_Finance'\n",
    "category_2 = '2_Politics'\n",
    "category_3 = '3_Sports'\n",
    "category_4 = '4_Health'\n",
    "\n",
    "# 合并所有国家的情感分析数据\n",
    "category = category_1\n",
    "\n",
    "path_TG = \"../Data/Sentiment_Scores/ClassificationSentimentScores/\" + category + \"/TG_Sentiment_Scores/*.csv\"\n",
    "path_CNN = \"../Data/Sentiment_Scores/ClassificationSentimentScores/\" + category + \"/CNN_Sentiment_Scores/*.csv\"\n",
    "path_MW = \"../Data/Sentiment_Scores/ClassificationSentimentScores/\" + category + \"/MW_Sentiment_Scores/*.csv\"\n",
    "path_Reuters = \"../Data/Sentiment_Scores/ClassificationSentimentScores/\" + category + \"/Reuters_Sentiment_Scores/*.csv\"\n",
    "\n",
    "def process_files(path, exclude_suffix=None):\n",
    "    lst_files = []\n",
    "\n",
    "    for fname in glob.glob(path):\n",
    "        if exclude_suffix:\n",
    "            if not fname.endswith(exclude_suffix):\n",
    "                lst_files.append(fname)\n",
    "        else:\n",
    "            lst_files.append(fname)\n",
    "\n",
    "    lst_files = sorted(lst_files)\n",
    "\n",
    "    df_sentiment = pd.concat(map(pd.read_csv, lst_files), ignore_index=True)\n",
    "    df_sentiment = df_sentiment.sort_values(by=['Date', 'Country'], ascending=True)\n",
    "    df_sentiment = df_sentiment.drop(['Unnamed: 0'], axis=1)\n",
    "    df_sentiment['Date'] = pd.to_datetime(df_sentiment['Date'])\n",
    "    df_sentiment = df_sentiment[~(df_sentiment['Date'] < '2012-01-01')]\n",
    "\n",
    "    return df_sentiment\n",
    "\n",
    "# 处理数据\n",
    "df_TG_sentiment = process_files(path_TG, \"_original.csv\")\n",
    "df_CNN_sentiment = process_files(path_CNN, \"_original.csv\")\n",
    "df_MW_sentiment = process_files(path_MW, \"_original.csv\")\n",
    "df_Reuters_sentiment = process_files(path_Reuters, \"_original.csv\")\n",
    "\n",
    "df_TG_sentiment.to_csv(r'../Data/Sentiment_Scores/{0}.csv'.format('Merged Sentiment TG'))\n",
    "df_CNN_sentiment.to_csv(r'../Data/Sentiment_Scores/{0}.csv'.format('Merged Sentiment CNN'))\n",
    "df_MW_sentiment.to_csv(r'../Data/Sentiment_Scores/{0}.csv'.format('Merged Sentiment MW'))\n",
    "df_Reuters_sentiment.to_csv(r'../Data/Sentiment_Scores/{0}.csv'.format('Merged Sentiment Reuters'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e66ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
