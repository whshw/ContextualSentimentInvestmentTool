{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-22T16:08:33.972107Z",
     "start_time": "2023-07-22T16:08:30.612208Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "from   os import path\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from dateutil.parser import parse\n",
    "from dateutil.tz import gettz\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='transformers')\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# use the first GPU if available, otherwise use CPU\n",
    "device = torch.device(\"mps\"if torch.backends.mps.is_available()else \"cpu\")\n",
    "# device = 0 if torch.cuda.is_available() else -1\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def combineHeadlineText(row):\n",
    "    if isinstance(row[\"Headline\"], str):\n",
    "        return row[\"Headline\"] + \". \" + row[\"Text\"]\n",
    "    else:\n",
    "        return row[\"Text\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T15:18:03.488787Z",
     "start_time": "2023-07-22T15:18:03.472053Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/countries_integration/Australia_articles.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "Processing Australia_articles:   0%|          | 0/11105 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53a098f8581f4ec19e23369500e20b09"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'Data/MW_NER'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 40\u001B[0m\n\u001B[1;32m     38\u001B[0m df \u001B[38;5;241m=\u001B[39m df[df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCount\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     39\u001B[0m df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mdrop([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCount\u001B[39m\u001B[38;5;124m'\u001B[39m], axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 40\u001B[0m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m./Data/MW_NER/\u001B[39;49m\u001B[38;5;132;43;01m{0}\u001B[39;49;00m\u001B[38;5;124;43m.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcountry_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[0;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/pandas/core/generic.py:3720\u001B[0m, in \u001B[0;36mNDFrame.to_csv\u001B[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001B[0m\n\u001B[1;32m   3709\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ABCDataFrame) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_frame()\n\u001B[1;32m   3711\u001B[0m formatter \u001B[38;5;241m=\u001B[39m DataFrameFormatter(\n\u001B[1;32m   3712\u001B[0m     frame\u001B[38;5;241m=\u001B[39mdf,\n\u001B[1;32m   3713\u001B[0m     header\u001B[38;5;241m=\u001B[39mheader,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3717\u001B[0m     decimal\u001B[38;5;241m=\u001B[39mdecimal,\n\u001B[1;32m   3718\u001B[0m )\n\u001B[0;32m-> 3720\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataFrameRenderer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mformatter\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3721\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3722\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlineterminator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlineterminator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3723\u001B[0m \u001B[43m    \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3724\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3725\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3726\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3727\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquoting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquoting\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3728\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3729\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3730\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3731\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3732\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquotechar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquotechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3733\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3734\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdoublequote\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdoublequote\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3735\u001B[0m \u001B[43m    \u001B[49m\u001B[43mescapechar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mescapechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3736\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3737\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[0;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/pandas/io/formats/format.py:1189\u001B[0m, in \u001B[0;36mDataFrameRenderer.to_csv\u001B[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001B[0m\n\u001B[1;32m   1168\u001B[0m     created_buffer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1170\u001B[0m csv_formatter \u001B[38;5;241m=\u001B[39m CSVFormatter(\n\u001B[1;32m   1171\u001B[0m     path_or_buf\u001B[38;5;241m=\u001B[39mpath_or_buf,\n\u001B[1;32m   1172\u001B[0m     lineterminator\u001B[38;5;241m=\u001B[39mlineterminator,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1187\u001B[0m     formatter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfmt,\n\u001B[1;32m   1188\u001B[0m )\n\u001B[0;32m-> 1189\u001B[0m \u001B[43mcsv_formatter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m created_buffer:\n\u001B[1;32m   1192\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path_or_buf, StringIO)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/pandas/io/formats/csvs.py:241\u001B[0m, in \u001B[0;36mCSVFormatter.save\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;124;03mCreate the writer & save.\u001B[39;00m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;66;03m# apply compression and byte/text conversion\u001B[39;00m\n\u001B[0;32m--> 241\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    242\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    245\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    246\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    247\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    248\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handles:\n\u001B[1;32m    249\u001B[0m \n\u001B[1;32m    250\u001B[0m     \u001B[38;5;66;03m# Note: self.encoding is irrelevant here\u001B[39;00m\n\u001B[1;32m    251\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwriter \u001B[38;5;241m=\u001B[39m csvlib\u001B[38;5;241m.\u001B[39mwriter(\n\u001B[1;32m    252\u001B[0m         handles\u001B[38;5;241m.\u001B[39mhandle,\n\u001B[1;32m    253\u001B[0m         lineterminator\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlineterminator,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    258\u001B[0m         quotechar\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquotechar,\n\u001B[1;32m    259\u001B[0m     )\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/pandas/io/common.py:734\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    732\u001B[0m \u001B[38;5;66;03m# Only for write methods\u001B[39;00m\n\u001B[1;32m    733\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode \u001B[38;5;129;01mand\u001B[39;00m is_path:\n\u001B[0;32m--> 734\u001B[0m     \u001B[43mcheck_parent_directory\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    736\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m compression:\n\u001B[1;32m    737\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m compression \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzstd\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    738\u001B[0m         \u001B[38;5;66;03m# compression libraries do not like an explicit text-mode\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/pandas/io/common.py:597\u001B[0m, in \u001B[0;36mcheck_parent_directory\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m    595\u001B[0m parent \u001B[38;5;241m=\u001B[39m Path(path)\u001B[38;5;241m.\u001B[39mparent\n\u001B[1;32m    596\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m parent\u001B[38;5;241m.\u001B[39mis_dir():\n\u001B[0;32m--> 597\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\u001B[38;5;124mrf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot save file into a non-existent directory: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparent\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mOSError\u001B[0m: Cannot save file into a non-existent directory: 'Data/MW_NER'"
     ]
    }
   ],
   "source": [
    "lst_files = []\n",
    "\n",
    "Path = \"../Data/countries_integration/*.csv\"\n",
    "count = 0\n",
    "\n",
    "for fname in glob.glob(Path):\n",
    "    lst_files.append(fname)\n",
    "\n",
    "lst_files = sorted(lst_files)\n",
    "\n",
    "for file in lst_files:\n",
    "    file_name = os.path.basename(file)  # Get the file name from the full file path\n",
    "    country_name = os.path.splitext(file_name)[0]  # Remove the file extension\n",
    "\n",
    "    if not os.path.isfile('../Data/MW_NER/{0}.csv'.format(country_name)):\n",
    "        print(file)\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        if df.shape[0] != 0:\n",
    "            df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "            df = df.drop_duplicates(['Date','Headline'],keep= 'last')\n",
    "            df['Text'] = df['Text'].astype(str)\n",
    "            df['Text'] = df.apply(lambda row: combineHeadlineText(row), axis=1)\n",
    "            df['Date'] = df['Date'].str.replace(r'Published: ', ' ')\n",
    "            df['Date'] = df['Date'].str.replace(r'First', ' ')\n",
    "            df['Date'] = df['Date'].apply(lambda date_str: parse(date_str, tzinfos={'ET': gettz('America/New_York')}))\n",
    "            df['Date'] = df['Date'].dt.date   #change date format to YYYY-MM-DD\n",
    "            df = df.sort_values(by = ['Date'], ascending = True)\n",
    "\n",
    "            count = []\n",
    "            for i in tqdm(range(len(df)), desc=f\"Processing {country_name}\"):\n",
    "                ner_results = nlp(df[\"Text\"].iloc[i])\n",
    "                country_instances = [d for d in ner_results if (d['entity'] in \"B-ORG\") and (d['word'] in country_name) and (d['score'] > 0.98)]\n",
    "                count.append(len(country_instances))\n",
    "\n",
    "            df['Count'] = count\n",
    "            df = df[df['Count'] > 0]\n",
    "            df = df.drop(['Count'], axis = 1)\n",
    "            df.to_csv(r'../Data/MW_NER/{0}.csv'.format(country_name))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T15:37:42.651334Z",
     "start_time": "2023-07-22T15:26:13.835241Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def process_single_article(text, country_name):\n",
    "    ner_results = nlp(text)\n",
    "    country_instances = [d for d in ner_results if (d['entity'] in \"B-ORG\") and (d['word'] in country_name) and (d['score'] > 0.98)]\n",
    "    return len(country_instances)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T16:08:14.719445Z",
     "start_time": "2023-07-22T16:08:14.715154Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Find all csv files in the path\n",
    "csv_files = glob.glob('../Data/countries_integration/*.csv')\n",
    "\n",
    "# Sort the file names\n",
    "csv_files = sorted(csv_files)\n",
    "\n",
    "# Read the first csv file\n",
    "df = pd.read_csv(csv_files[0])\n",
    "\n",
    "# Get the first row of the DataFrame\n",
    "first_row = df.iloc[43]\n",
    "\n",
    "# Extract the 'Date', 'Headline' and 'Text' columns\n",
    "date = first_row['Date']\n",
    "headline = first_row['Headline']\n",
    "text = first_row['Text']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T16:16:14.150265Z",
     "start_time": "2023-07-22T16:16:13.850331Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "ner_results = nlp(headline + text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T16:17:36.097624Z",
     "start_time": "2023-07-22T16:17:35.929547Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'entity': 'B-ORG',\n  'score': 0.9932053,\n  'index': 1,\n  'word': 'AN',\n  'start': 0,\n  'end': 2},\n {'entity': 'I-ORG',\n  'score': 0.992149,\n  'index': 2,\n  'word': '##Z',\n  'start': 2,\n  'end': 3},\n {'entity': 'B-ORG',\n  'score': 0.99892753,\n  'index': 4,\n  'word': 'RB',\n  'start': 9,\n  'end': 11},\n {'entity': 'I-ORG',\n  'score': 0.9988914,\n  'index': 5,\n  'word': '##A',\n  'start': 11,\n  'end': 12},\n {'entity': 'B-ORG',\n  'score': 0.9988292,\n  'index': 20,\n  'word': 'Australia',\n  'start': 56,\n  'end': 65},\n {'entity': 'I-ORG',\n  'score': 0.99927264,\n  'index': 21,\n  'word': '&',\n  'start': 66,\n  'end': 67},\n {'entity': 'I-ORG',\n  'score': 0.9993352,\n  'index': 22,\n  'word': 'New',\n  'start': 68,\n  'end': 71},\n {'entity': 'I-ORG',\n  'score': 0.9992262,\n  'index': 23,\n  'word': 'Zealand',\n  'start': 72,\n  'end': 79},\n {'entity': 'I-ORG',\n  'score': 0.999316,\n  'index': 24,\n  'word': 'Banking',\n  'start': 80,\n  'end': 87},\n {'entity': 'I-ORG',\n  'score': 0.99929905,\n  'index': 25,\n  'word': 'Group',\n  'start': 88,\n  'end': 93},\n {'entity': 'I-ORG',\n  'score': 0.99907744,\n  'index': 26,\n  'word': 'Ltd',\n  'start': 94,\n  'end': 97},\n {'entity': 'B-ORG',\n  'score': 0.99583226,\n  'index': 29,\n  'word': 'AN',\n  'start': 100,\n  'end': 102},\n {'entity': 'I-ORG',\n  'score': 0.98822916,\n  'index': 30,\n  'word': '##Z',\n  'start': 102,\n  'end': 103},\n {'entity': 'I-ORG',\n  'score': 0.5856561,\n  'index': 31,\n  'word': '.',\n  'start': 103,\n  'end': 104},\n {'entity': 'I-ORG',\n  'score': 0.99690634,\n  'index': 32,\n  'word': 'AU',\n  'start': 104,\n  'end': 106},\n {'entity': 'B-MISC',\n  'score': 0.9997466,\n  'index': 38,\n  'word': 'Australian',\n  'start': 133,\n  'end': 143},\n {'entity': 'B-LOC',\n  'score': 0.9997409,\n  'index': 65,\n  'word': 'Australia',\n  'start': 273,\n  'end': 282},\n {'entity': 'B-ORG',\n  'score': 0.99879766,\n  'index': 78,\n  'word': 'Reserve',\n  'start': 336,\n  'end': 343},\n {'entity': 'I-ORG',\n  'score': 0.9993382,\n  'index': 79,\n  'word': 'Bank',\n  'start': 344,\n  'end': 348},\n {'entity': 'I-ORG',\n  'score': 0.9992987,\n  'index': 80,\n  'word': 'of',\n  'start': 349,\n  'end': 351},\n {'entity': 'I-ORG',\n  'score': 0.99930394,\n  'index': 81,\n  'word': 'Australia',\n  'start': 352,\n  'end': 361},\n {'entity': 'B-MISC',\n  'score': 0.9997414,\n  'index': 114,\n  'word': 'Australian',\n  'start': 491,\n  'end': 501},\n {'entity': 'B-ORG',\n  'score': 0.9984345,\n  'index': 126,\n  'word': 'RB',\n  'start': 553,\n  'end': 555},\n {'entity': 'I-ORG',\n  'score': 0.9982514,\n  'index': 127,\n  'word': '##A',\n  'start': 555,\n  'end': 556},\n {'entity': 'B-ORG',\n  'score': 0.9973816,\n  'index': 169,\n  'word': 'AN',\n  'start': 770,\n  'end': 772},\n {'entity': 'I-ORG',\n  'score': 0.99851054,\n  'index': 170,\n  'word': '##Z',\n  'start': 772,\n  'end': 773},\n {'entity': 'B-LOC',\n  'score': 0.9995554,\n  'index': 184,\n  'word': 'Australia',\n  'start': 835,\n  'end': 844},\n {'entity': 'B-ORG',\n  'score': 0.9981427,\n  'index': 235,\n  'word': 'RB',\n  'start': 1089,\n  'end': 1091},\n {'entity': 'I-ORG',\n  'score': 0.9981115,\n  'index': 236,\n  'word': '##A',\n  'start': 1091,\n  'end': 1092},\n {'entity': 'B-ORG',\n  'score': 0.9991461,\n  'index': 291,\n  'word': 'Goldman',\n  'start': 1392,\n  'end': 1399},\n {'entity': 'I-ORG',\n  'score': 0.99940324,\n  'index': 292,\n  'word': 'Sachs',\n  'start': 1400,\n  'end': 1405},\n {'entity': 'I-ORG',\n  'score': 0.99936825,\n  'index': 293,\n  'word': 'Group',\n  'start': 1406,\n  'end': 1411},\n {'entity': 'I-ORG',\n  'score': 0.99941456,\n  'index': 294,\n  'word': 'Inc',\n  'start': 1412,\n  'end': 1415},\n {'entity': 'B-ORG',\n  'score': 0.98708224,\n  'index': 299,\n  'word': 'G',\n  'start': 1420,\n  'end': 1421},\n {'entity': 'I-ORG',\n  'score': 0.913189,\n  'index': 300,\n  'word': '##S',\n  'start': 1421,\n  'end': 1422},\n {'entity': 'B-PER',\n  'score': 0.99957937,\n  'index': 307,\n  'word': 'Tim',\n  'start': 1450,\n  'end': 1453},\n {'entity': 'I-PER',\n  'score': 0.99967384,\n  'index': 308,\n  'word': 'Too',\n  'start': 1454,\n  'end': 1457},\n {'entity': 'I-PER',\n  'score': 0.9991948,\n  'index': 309,\n  'word': '##hey',\n  'start': 1457,\n  'end': 1460},\n {'entity': 'B-MISC',\n  'score': 0.99970394,\n  'index': 335,\n  'word': 'Australian',\n  'start': 1563,\n  'end': 1573},\n {'entity': 'B-ORG',\n  'score': 0.99665314,\n  'index': 364,\n  'word': 'AN',\n  'start': 1748,\n  'end': 1750},\n {'entity': 'I-ORG',\n  'score': 0.9985342,\n  'index': 365,\n  'word': '##Z',\n  'start': 1750,\n  'end': 1751},\n {'entity': 'B-PER',\n  'score': 0.9965178,\n  'index': 371,\n  'word': 'Caroline',\n  'start': 1766,\n  'end': 1774},\n {'entity': 'I-PER',\n  'score': 0.99918824,\n  'index': 372,\n  'word': 'He',\n  'start': 1775,\n  'end': 1777},\n {'entity': 'I-PER',\n  'score': 0.8371813,\n  'index': 373,\n  'word': '##ns',\n  'start': 1777,\n  'end': 1779},\n {'entity': 'I-PER',\n  'score': 0.9167949,\n  'index': 374,\n  'word': '##haw',\n  'start': 1779,\n  'end': 1782}]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T16:17:52.976153Z",
     "start_time": "2023-07-22T16:17:52.970590Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
